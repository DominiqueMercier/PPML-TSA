{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "############ Tensforflow config ############\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "############## Import modules ##############\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX: (2520, 500, 1)\n",
      "ValX: (1081, 500, 1)\n",
      "TestX: (3601, 500, 1)\n",
      "Classes: 2\n"
     ]
    }
   ],
   "source": [
    "from modules import ucr_loader, utils\n",
    "# get all datasets\n",
    "root = '../../../data/'\n",
    "dataset_dict = ucr_loader.get_datasets(root, prefix='**/')\n",
    "# retrieve data\n",
    "dataset_name = 'FordA'\n",
    "trainX, trainY, testX, testY = ucr_loader.load_data(dataset_dict[dataset_name])\n",
    "# preprocess data\n",
    "trainX, trainY, testX, testY = ucr_loader.preprocess_data(trainX, trainY, testX, testY, normalize=False, standardize=True)\n",
    "# additional preprocessing\n",
    "trainX, trainY, valX, valY = utils.perform_datasplit(trainX, trainY, test_split=0.3)\n",
    "n_classes = len(np.unique(trainY))\n",
    "# Shapes\n",
    "print('TrainX:', trainX.shape)\n",
    "print('ValX:', valX.shape)\n",
    "print('TestX:', testX.shape)\n",
    "print('Classes:', n_classes)\n",
    "\n",
    "# uncomment to use the save folders\n",
    "#model_dir, result_dir = utils.maybe_create_dirs(dataset_name, root='../../../', dirs=['models', 'results'], return_paths=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training using a model with privacy preserving method (Differential Privacy)\n",
    "- hyper parameters to ad noise and clip gradients are used for differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size, learning_rate = 100, 32, 0.2\n",
    "#privacy parameter\n",
    "l2_norm_clip, noise_multiplier, num_microbatches = 1.0, 0.2, batch_size\n",
    "if batch_size % num_microbatches != 0:\n",
    "    num_microbatches = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size = int(trainX.shape[0]/batch_size) * batch_size, int(valX.shape[0]/batch_size) * batch_size\n",
    "trainXm, trainYm, valXm, valYm = trainX[:train_size], trainY[:train_size], valX[:val_size], valY[:val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=train_size, batch_size=batch_size, noise_multiplier=noise_multiplier, epochs=epochs, delta=1/train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model_definition import AlexNet\n",
    "from modules.DM import trainer_differential_privacy\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "\n",
    "# uncomment to save the model\n",
    "model_path = None# os.path.join(model_dir, 'AlexNet_differential_1d_batch-' + str(batch_size) + '_l2-' + str(l2_norm_clip) + '_noise-' + str(noise_multiplier) + '.h5')\n",
    "model = AlexNet().build_1d(trainX.shape[1:], n_classes, activation='softmax', verbose=1)\n",
    "optimizer = DPKerasSGDOptimizer(l2_norm_clip=l2_norm_clip, noise_multiplier=noise_multiplier, num_microbatches=num_microbatches, learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "trainer_differential_privacy.traintf(sess, model, trainXm, trainYm, validation_data=(valXm, valYm), \n",
    "                                        epochs=epochs, batch_size=batch_size, model_path=model_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(testX.shape[0]/batch_size) * batch_size\n",
    "testXm = testX\n",
    "if test_size < testX.shape[0]:\n",
    "    fill = np.zeros((batch_size - (testX.shape[0] - test_size), *testX.shape[1:]))\n",
    "    testXm = np.concatenate([testX, fill], axis=0)\n",
    "# uncomment to save the model\n",
    "report_path = None#os.path.join(result_dir, 'AlexNet_differential_1d_batch-' + str(batch_size) + '_l2-' + str(l2_norm_clip) + '_noise-' + str(noise_multiplier) + '_report.txt')\n",
    "preds = np.argmax(model.predict(testXm, batch_size=batch_size, verbose=1), axis=1)\n",
    "utils.compute_classification_report(testY, preds[:testX.shape[0]], save=report_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('tf2_4')",
   "metadata": {
    "interpreter": {
     "hash": "788660a0612e77e24ebe3e72288f65d4e4e7242c0073a8e4dad0a15c2c8da2dc"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
