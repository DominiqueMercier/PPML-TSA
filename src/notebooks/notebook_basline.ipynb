{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('tf2_4': virtualenvwrapper)"
  },
  "interpreter": {
   "hash": "788660a0612e77e24ebe3e72288f65d4e4e7242c0073a8e4dad0a15c2c8da2dc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "############ Tensforflow config ############\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.compat.v1.Session(config=config)\n",
    "#tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "############## Import modules ##############\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TrainX: (995, 182, 3)\nValX: (427, 182, 3)\nTestX: (1436, 182, 3)\nClasses: 20\n"
     ]
    }
   ],
   "source": [
    "from modules import ucr_loader, utils\n",
    "# get all datasets\n",
    "root = '../../data/'\n",
    "dataset_dict = ucr_loader.get_datasets(root, prefix='**/')\n",
    "# retrieve data\n",
    "dataset_name = 'CharacterTrajectories'\n",
    "trainX, trainY, testX, testY = ucr_loader.load_data(dataset_dict[dataset_name])\n",
    "# preprocess data\n",
    "trainX, trainY, testX, testY = ucr_loader.preprocess_data(trainX, trainY, testX, testY, normalize=False, standardize=True)\n",
    "# additional preprocessing\n",
    "trainX, trainY, valX, valY = utils.perform_datasplit(trainX, trainY, test_split=0.3)\n",
    "n_classes = len(np.unique(trainY))\n",
    "# Shapes\n",
    "print('TrainX:', trainX.shape)\n",
    "print('ValX:', valX.shape)\n",
    "print('TestX:', testX.shape)\n",
    "print('Classes:', n_classes)\n",
    "\n",
    "# uncomment to use the save folders\n",
    "#model_dir, result_dir = utils.maybe_create_dirs(dataset_name, root='../../', dirs=['models', 'results'], return_paths=True, verbose=1)"
   ]
  },
  {
   "source": [
    "Training using a baseline model without any privacy preserving methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 46, 96)            3264      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 46, 96)            384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 23, 96)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 23, 256)           123136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 12, 384)           295296    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 384)           1536      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 12, 384)           147840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 384)           1536      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 12, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              6295552   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                81940     \n",
      "=================================================================\n",
      "Total params: 23,832,404\n",
      "Trainable params: 23,829,652\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 46, 96)            3264      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 46, 96)            384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 23, 96)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 23, 256)           123136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 12, 384)           295296    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 384)           1536      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 12, 384)           147840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 384)           1536      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 12, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              6295552   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                81940     \n",
      "=================================================================\n",
      "Total params: 23,832,404\n",
      "Trainable params: 23,829,652\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "125/125 [==============================] - 3s 11ms/step - loss: 2.3230 - accuracy: 0.4359 - val_loss: 1.8922 - val_accuracy: 0.5035\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3378 - accuracy: 0.8941 - val_loss: 0.2522 - val_accuracy: 0.9672\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2028 - accuracy: 0.9454 - val_loss: 0.1047 - val_accuracy: 0.9625\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.1480 - accuracy: 0.9576 - val_loss: 0.0898 - val_accuracy: 0.9696\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.1065 - accuracy: 0.9655 - val_loss: 0.3567 - val_accuracy: 0.9297\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.1398 - accuracy: 0.9534 - val_loss: 0.1024 - val_accuracy: 0.9696\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0732 - accuracy: 0.9708 - val_loss: 0.0775 - val_accuracy: 0.9719\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.1201 - val_accuracy: 0.9672\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9758 - val_loss: 0.0563 - val_accuracy: 0.9859\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0536 - accuracy: 0.9863 - val_loss: 0.0578 - val_accuracy: 0.9859\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9893 - val_loss: 0.0626 - val_accuracy: 0.9813\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9925 - val_loss: 0.0543 - val_accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9804 - val_loss: 0.8899 - val_accuracy: 0.9016\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0678 - accuracy: 0.9776 - val_loss: 0.1525 - val_accuracy: 0.9649\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9822 - val_loss: 0.0500 - val_accuracy: 0.9813\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.0477 - val_accuracy: 0.9859\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9906\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0344 - val_accuracy: 0.9883\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0488 - val_accuracy: 0.9836\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0256 - val_accuracy: 0.9883\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.0348 - val_accuracy: 0.9883\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0333 - val_accuracy: 0.9836\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0286 - val_accuracy: 0.9859\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.5186 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0815 - accuracy: 0.9859 - val_loss: 0.0394 - val_accuracy: 0.9836\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0242 - val_accuracy: 0.9859\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0308 - val_accuracy: 0.9906\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9973 - val_loss: 0.0284 - val_accuracy: 0.9906\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9906\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0348 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.0313 - val_accuracy: 0.9906\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9906\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9906\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9859\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9883\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "from modules.model_definition import AlexNet\n",
    "from modules import model_trainer\n",
    "\n",
    "# uncomment to save the model\n",
    "model_path = None# os.path.join(model_dir, 'AlexNet_1d_batch-' + str(options.batch_size) + '.h5')\n",
    "model = AlexNet().build_1d(trainX.shape[1:], n_classes, activation='softmax', verbose=1)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_trainer.train(model, trainX, trainY, validation_data=(valX, valY), epochs=100, batch_size=8, model_path=model_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "45/45 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        86\n",
      "           1     0.9538    0.9538    0.9538        65\n",
      "           2     1.0000    0.9859    0.9929        71\n",
      "           3     1.0000    1.0000    1.0000        66\n",
      "           4     1.0000    1.0000    1.0000        62\n",
      "           5     1.0000    0.9833    0.9916        60\n",
      "           6     1.0000    1.0000    1.0000        67\n",
      "           7     0.9851    1.0000    0.9925        66\n",
      "           8     1.0000    1.0000    1.0000        78\n",
      "           9     0.9836    0.9524    0.9677        63\n",
      "          10     1.0000    1.0000    1.0000        69\n",
      "          11     1.0000    1.0000    1.0000        71\n",
      "          12     1.0000    1.0000    1.0000        86\n",
      "          13     0.9861    1.0000    0.9930        71\n",
      "          14     1.0000    1.0000    1.0000        79\n",
      "          15     0.9894    1.0000    0.9947        93\n",
      "          16     1.0000    1.0000    1.0000        69\n",
      "          17     0.9841    0.9688    0.9764        64\n",
      "          18     1.0000    1.0000    1.0000        87\n",
      "          19     0.9692    1.0000    0.9844        63\n",
      "\n",
      "    accuracy                         0.9930      1436\n",
      "   macro avg     0.9926    0.9922    0.9923      1436\n",
      "weighted avg     0.9931    0.9930    0.9930      1436\n",
      "\n",
      "Save Location: AlexNet_mean-report.txt\n"
     ]
    }
   ],
   "source": [
    "# uncomment to save the model\n",
    "report_path = None#os.path.join(result_dir, 'AlexNet_1d_batch-' + str(options.batch_size) + '_report.txt')\n",
    "preds = np.argmax(model.predict(testX, batch_size=32, verbose=1), axis=1)\n",
    "utils.compute_classification_report(testY, preds, save=report_path, verbose=1, store_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}